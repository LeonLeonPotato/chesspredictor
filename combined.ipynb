{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0015\n",
    "weight_decay = 0.0001\n",
    "batch_size = 512\n",
    "epochs = 6\n",
    "\n",
    "history_count = 4\n",
    "filter_size = 64\n",
    "main_model_blocks = 4\n",
    "move_processor_blocks = 8\n",
    "use_batchnorm = False\n",
    "\n",
    "min_elo_win = 2000\n",
    "min_elo_tie = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q python-chess\n",
    "! pip install -q kaggle\n",
    "\n",
    "! mkdir ~/.kaggle\n",
    "! echo '{\"username\":\"threetnt\",\"key\":\"7454bbee8bfde646c02f2a915ea5d02a\"}' > ~/.kaggle/kaggle.json\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle datasets download -d milesh1/35-million-chess-games\n",
    "! unzip -p 35-million-chess-games.zip all_with_filtered_anotations_since1998.txt > rawdata.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chess.pgn\n",
    "import io\n",
    "import time\n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def board_to_array(board):\n",
    "    board_state = np.zeros((6, 8, 8), dtype=np.int8)\n",
    "\n",
    "    piece_dict = {\n",
    "        'P': 0,  # White Pawn\n",
    "        'R': 1,  # White Rook\n",
    "        'N': 2,  # White Knight\n",
    "        'B': 3,  # White Bishop\n",
    "        'Q': 4,  # White Queen\n",
    "        'K': 5,  # White King\n",
    "    }\n",
    "\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            piece = board.piece_at(chess.square(i, j))\n",
    "\n",
    "            if piece:\n",
    "                piece_str = str(piece)\n",
    "                color = int(piece_str.isupper())\n",
    "                layer = piece_dict[piece_str.upper()]\n",
    "                board_state[layer, 7-j, i] = color*2-1\n",
    "            \n",
    "    return board_state\n",
    "\n",
    "def pgn_to_states(p):\n",
    "    game_states = []\n",
    "\n",
    "    p = io.StringIO(p)\n",
    "    game = chess.pgn.read_game(p)\n",
    "    p.close()\n",
    "\n",
    "    board = game.board()\n",
    "    for move in game.mainline_moves():\n",
    "        board.push(move)\n",
    "        board_state = board_to_array(board)\n",
    "        game_states.append(board_state)\n",
    "\n",
    "    return game_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lambda f:f()\n",
    "def process():\n",
    "    with open(\"rawdata.txt\", \"r\") as f:\n",
    "        data = f.readlines()[5:]\n",
    "\n",
    "    filehandle = open(\"chess_processed_small.csv\", \"w\")\n",
    "    filehandle.write(\"winner,white_elo,black_elo,diff,pgn\\n\")\n",
    "\n",
    "    def convert_to_pgn(move_sequence):\n",
    "        moves = move_sequence.split(\" \")\n",
    "        pgn_moves = []\n",
    "        for i in range(0, len(moves), 2):\n",
    "            move_number = i // 2 + 1\n",
    "            white_move = moves[i].split('.')[1]\n",
    "            black_move = moves[i+1].split('.')[1] if i + 1 < len(moves) and '.' in moves[i+1] else ''\n",
    "            pgn_moves.append(f\"{move_number}.{white_move} {black_move}\")\n",
    "        return \" \".join(pgn_moves)\n",
    "\n",
    "    _time = time.time()\n",
    "    _processed, _total = 0, 0\n",
    "\n",
    "    processed_cache = \"\"\n",
    "    for line in data:\n",
    "        metadata, pgn = line.split(\" ### \")\n",
    "        pgn = pgn.strip()\n",
    "        metadata = metadata.strip().split(\" \")\n",
    "        \n",
    "        winner = metadata[2]\n",
    "        if \"blen_false\" in metadata[15] and metadata[3] != \"None\" and metadata[4] != \"None\":\n",
    "            welo, belo = int(metadata[3]), int(metadata[4])\n",
    "            if pgn.endswith(\"#\"):\n",
    "                if welo < min_elo_win or belo < min_elo_win:\n",
    "                    continue\n",
    "            elif winner == \"1/2-1/2\":\n",
    "                if welo < min_elo_tie or belo < min_elo_tie:\n",
    "                    continue\n",
    "            else: continue\n",
    "\n",
    "            pgn = convert_to_pgn(pgn)\n",
    "            if winner == \"1-0\": \n",
    "                winner = 1\n",
    "            elif winner == \"0-1\": \n",
    "                winner = -1\n",
    "            else: \n",
    "                winner = 0\n",
    "            processed_cache += f\"{winner},{welo},{belo},{welo - belo},{pgn}\\n\"\n",
    "            _processed += 1\n",
    "        _total += 1\n",
    "\n",
    "        if time.time() - _time > 0.2:\n",
    "            print(f\"{_processed} / {_total}\")\n",
    "            _time = time.time()\n",
    "\n",
    "        if _processed > 5000: # Too much data will overflow the RAM\n",
    "            break\n",
    "\n",
    "    print(\"done\")\n",
    "    filehandle.write(processed_cache)\n",
    "    filehandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process():\n",
    "    if 'data' in os.listdir():\n",
    "        if 'X.npy' in os.listdir('data') and 'Y.npy' in os.listdir('data'):\n",
    "            return np.load('data/X.npy'), np.load('data/Y.npy')\n",
    "    else:\n",
    "        os.mkdir('data')\n",
    "\n",
    "    df = pd.read_csv('chess_processed_small.csv')\n",
    "\n",
    "    winner_w = df[df['winner'] == 1]\n",
    "    winner_b = df[df['winner'] == -1]\n",
    "    tie = df[df['winner'] == 0]\n",
    "\n",
    "    minlen = min(len(winner_w), len(winner_b), len(tie))\n",
    "    winner_w = resample(winner_w, replace=False, n_samples=minlen, random_state=1337)\n",
    "    winner_b = resample(winner_b, replace=False, n_samples=minlen, random_state=1337)\n",
    "    tie = resample(tie, replace=False, n_samples=minlen, random_state=1337)\n",
    "\n",
    "    df:pd.DataFrame = pd.concat([winner_w, winner_b, tie])\n",
    "    print(df['winner'].value_counts())\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    t = time.time()\n",
    "    done = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        states = pgn_to_states(row['pgn'])\n",
    "        winner = row['winner']\n",
    "        \n",
    "        laststates = [np.zeros((6, 8, 8), dtype=np.int8) for i in range(4)]\n",
    "        for state in states:\n",
    "            del laststates.pop(0)\n",
    "            laststates.append(state)\n",
    "            X.append(np.array(laststates).reshape((6*history_count, 8, 8)))\n",
    "            Y.append(winner)\n",
    "        \n",
    "        if time.time() - t > 1:\n",
    "            print(\"Done:\", done, \"| Time elapsed:\", time.time() - t)\n",
    "            t = time.time()\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    np.save('data/X.npy', X)\n",
    "    np.save('data/Y.npy', Y)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "X, Y = process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Basic block of a ResNet\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(filter_size, filter_size, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(filter_size, filter_size, kernel_size=3, padding=1),\n",
    "        ) if not use_batchnorm else nn.Sequential(\n",
    "            nn.Conv2d(filter_size, filter_size, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(filter_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(filter_size, filter_size, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(filter_size),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.convs(x)\n",
    "        x1 += x\n",
    "        return F.leaky_relu(x1)\n",
    "\n",
    "# Processes a single state from the last 4 states\n",
    "class MoveProcessor(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(6, filter_size, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            *[ResBlock() for _ in range(move_processor_blocks)],\n",
    "            nn.Conv2d(filter_size, filter_size, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.convs(x)\n",
    "\n",
    "# The main model\n",
    "class ChessNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.move_processor = MoveProcessor()\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(filter_size * history_count, filter_size, kernel_size=1, padding=0),\n",
    "            *[ResBlock() for _ in range(main_model_blocks)],\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*8*8, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # We do this because it leverages the GPU more\n",
    "        x = self.move_processor(\n",
    "            x.reshape(x.shape[0]*history_count, 6, 8, 8)\n",
    "        ).reshape(\n",
    "            x.shape[0], filter_size*history_count, 8, 8\n",
    "        )\n",
    "        return self.convs(x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = x.reshape(1, 6*history_count, 8, 8)\n",
    "        return self.forward(x).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torched",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
